{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939b795b-4f4d-405d-9224-3373d3b49e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downloading gesture archives...\")\n",
    "!wget \"https://rndml-team-cv.obs.ru-moscow-1.hc.sbercloud.ru/datasets/hagrid/hagrid_dataset_new_554800/hagrid_dataset/fist.zip\" -O _fist.zip\n",
    "!wget \"https://rndml-team-cv.obs.ru-moscow-1.hc.sbercloud.ru/datasets/hagrid/hagrid_dataset_new_554800/hagrid_dataset/palm.zip\" -O _palm.zip\n",
    "!wget \"https://rndml-team-cv.obs.ru-moscow-1.hc.sbercloud.ru/datasets/hagrid/hagrid_dataset_new_554800/hagrid_dataset/like.zip\" -O _like.zip\n",
    "!wget \"https://rndml-team-cv.obs.ru-moscow-1.hc.sbercloud.ru/datasets/hagrid/hagrid_dataset_new_554800/hagrid_dataset/dislike.zip\" -O _dislike.zip\n",
    "!wget \"https://rndml-team-cv.obs.ru-moscow-1.hc.sbercloud.ru/datasets/hagrid_v2/hagrid_v2_zip/no_gesture.zip\" -O _no_gesture.zip # For our 'none' class\n",
    "\n",
    "print(\"\\nDownloading annotations...\")\n",
    "!wget \"https://rndml-team-cv.obs.ru-moscow-1.hc.sbercloud.ru/datasets/hagrid_v2/annotations_with_landmarks/annotations.zip\" -O ann_train_val.zip\n",
    "\n",
    "print(\"\\nAll downloads complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fce9e6b2-1666-4534-9ae8-14d4b78c5a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting unzip.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile unzip.py\n",
    "import os\n",
    "import zipfile\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "BASE_PATH = \".\" \n",
    "TEMP_IMAGES_PATH = os.path.join(BASE_PATH, \"temp_images\")\n",
    "SORTED_DATA_PATH = os.path.join(BASE_PATH, \"data\")\n",
    "ANNOTATIONS_PATH = os.path.join(BASE_PATH, \"annotations\")\n",
    "\n",
    "# Create directories inside the current folder\n",
    "os.makedirs(TEMP_IMAGES_PATH, exist_ok=True)\n",
    "os.makedirs(SORTED_DATA_PATH, exist_ok=True)\n",
    "os.makedirs(ANNOTATIONS_PATH, exist_ok=True)\n",
    "\n",
    "print(\"Unzipping all downloaded archives...\")\n",
    "all_files_in_dir = os.listdir(BASE_PATH)\n",
    "\n",
    "for filename in all_files_in_dir:\n",
    "    if filename.endswith('.zip'):\n",
    "        print(f\"  - Unzipping {filename}...\")\n",
    "        file_path = os.path.join(BASE_PATH, filename)\n",
    "        \n",
    "        # Unzip annotations to ANNOTATIONS_PATH\n",
    "        try: \n",
    "            if 'ann_train_val' in filename:\n",
    "                with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(ANNOTATIONS_PATH)\n",
    "            else:\n",
    "                with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(TEMP_IMAGES_PATH)\n",
    "            os.remove(file_path)\n",
    "            print(f\"    - Deleted {filename} to save space.\")\n",
    "        except zipfile.BadZipFile:\n",
    "            print(f\"❌ WARNING: Could not unzip {filename}. It may be corrupt. Skipping.\")\n",
    "print(\"Unzipping complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8631f28e-cc0e-4683-9fb9-13963b84180c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping all downloaded archives...\n",
      "Unzipping complete.\n"
     ]
    }
   ],
   "source": [
    "!python unzip.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9a2090-c41c-406d-83ce-c657d8aa802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf data/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "905e0fe4-012b-4a41-9d9d-86dfbc7a41af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sort.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sort.py\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "BASE_PATH = \".\"\n",
    "SORTED_DATA_PATH = os.path.join(BASE_PATH, \"data\")\n",
    "ANNOTATIONS_PATH = os.path.join(BASE_PATH, \"annotations\")\n",
    "TEMP_IMAGES_PATH = os.path.join(BASE_PATH, \"temp_images\")\n",
    "\n",
    "files_moved_count = 0\n",
    "print(\"Starting the sorting process...\")\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    split_annotations_dir = os.path.join(ANNOTATIONS_PATH, \"annotations\", split)\n",
    "    print(f\"\\nProcessing '{split}' split...\")\n",
    "    \n",
    "    if not os.path.exists(split_annotations_dir):\n",
    "        print(f\"  - WARNING: Directory not found: {split_annotations_dir}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    json_files = [f for f in os.listdir(split_annotations_dir) if f.endswith('.json')]\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        gesture_name = os.path.splitext(json_file)[0]\n",
    "        final_dest_folder = os.path.join(SORTED_DATA_PATH, split, gesture_name)\n",
    "        os.makedirs(final_dest_folder, exist_ok=True)\n",
    "        \n",
    "        with open(os.path.join(split_annotations_dir, json_file), 'r') as f:\n",
    "            annotations = json.load(f)\n",
    "\n",
    "        for image_id in annotations:\n",
    "            # Add the .jpg file extension to the image ID to create the full filename\n",
    "            image_filename = f\"{image_id}.jpg\"            \n",
    "            source_image_path = \"\"\n",
    "            if gesture_name == 'no_gesture':\n",
    "                # Use the new filename variable to build the path\n",
    "                source_image_path = os.path.join(TEMP_IMAGES_PATH, image_filename)\n",
    "            else:\n",
    "                # Use the new filename variable to build the path\n",
    "                source_image_path = os.path.join(TEMP_IMAGES_PATH, gesture_name, image_filename)\n",
    "\n",
    "            dest_image_path = os.path.join(final_dest_folder, image_filename)\n",
    "\n",
    "            if os.path.exists(source_image_path):\n",
    "                shutil.move(source_image_path, dest_image_path)\n",
    "                files_moved_count += 1\n",
    "            # else:\n",
    "            #     print(f\"  - WARNING: Source image not found at {source_image_path}\")\n",
    "            #     pass\n",
    "\n",
    "print(f\"\\n✅ Sorting complete! Total files moved: {files_moved_count}\")\n",
    "\n",
    "print(\"\\nInitiating cleanup phase...\")\n",
    "\n",
    "if files_moved_count > 0:\n",
    "    print(f\"Cleanup condition met ({files_moved_count} files were moved). Deleting temporary folders.\")\n",
    "    if os.path.exists(TEMP_IMAGES_PATH):\n",
    "        shutil.rmtree(TEMP_IMAGES_PATH)\n",
    "    if os.path.exists(ANNOTATIONS_PATH):\n",
    "        shutil.rmtree(ANNOTATIONS_PATH)\n",
    "    print(\"✅ Cleanup finished.\")\n",
    "else:\n",
    "    print(\"❌ WARNING: Cleanup condition not met. No files were moved during sorting.\")\n",
    "    print(\"      The temporary folders will NOT be deleted for debugging.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "272b3f7c-26c7-4fce-80fa-9924b313bb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the sorting process...\n",
      "\n",
      "Processing 'train' split...\n",
      "\n",
      "Processing 'val' split...\n",
      "\n",
      "Processing 'test' split...\n",
      "\n",
      "✅ Sorting complete! Total files moved: 104661\n",
      "\n",
      "Initiating cleanup phase...\n",
      "Cleanup condition met (104661 files were moved). Deleting temporary folders.\n",
      "✅ Cleanup finished.\n"
     ]
    }
   ],
   "source": [
    "!python sort.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d55fad54-2753-4ab5-a1b6-e0b369cf3b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cleanup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cleanup.py\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "GESTURES_TO_KEEP = {\n",
    "    'fist', \n",
    "    'like', \n",
    "    'no_gesture', \n",
    "    'palm'\n",
    "}\n",
    "\n",
    "DATA_PATH = \"data\"\n",
    "\n",
    "print(\"Starting Cleanup Script\")\n",
    "\n",
    "if not os.path.isdir(DATA_PATH):\n",
    "    print(f\"Error: Data directory not found at '{DATA_PATH}'. Exiting.\")\n",
    "else:\n",
    "    # Loop through each split directory (train, val, test)\n",
    "    for split_name in os.listdir(DATA_PATH):\n",
    "        split_dir_path = os.path.join(DATA_PATH, split_name)\n",
    "        \n",
    "        if os.path.isdir(split_dir_path):\n",
    "            print(f\"\\nProcessing directory: {split_dir_path}\")\n",
    "            \n",
    "            # Loop through each gesture folder in the split directory\n",
    "            for gesture_name in os.listdir(split_dir_path):\n",
    "                gesture_folder_path = os.path.join(split_dir_path, gesture_name)\n",
    "                \n",
    "                # Check if the folder is actually a directory and NOT in our keep list\n",
    "                if os.path.isdir(gesture_folder_path) and gesture_name not in GESTURES_TO_KEEP:\n",
    "                    try:\n",
    "                        print(f\"  - Deleting unwanted folder: {gesture_folder_path}\")\n",
    "                        shutil.rmtree(gesture_folder_path)\n",
    "                    except OSError as e:\n",
    "                        print(f\"  - Error deleting {gesture_folder_path} : {e.strerror}\")\n",
    "\n",
    "print(\"\\n--- Cleanup Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a6540cc-0e4b-436e-ac13-df484b9e5ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Cleanup Script\n",
      "\n",
      "Processing directory: data/train\n",
      "  - Deleting unwanted folder: data/train/dislike\n",
      "\n",
      "Processing directory: data/test\n",
      "  - Deleting unwanted folder: data/test/dislike\n",
      "\n",
      "Processing directory: data/val\n",
      "  - Deleting unwanted folder: data/val/dislike\n",
      "\n",
      "--- Cleanup Complete ---\n"
     ]
    }
   ],
   "source": [
    "!python cleanup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e282c409-1926-442e-899d-6f90cc92cf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19fccb73-a3a8-498d-9374-2d253c3198ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# setup and configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "data_dir = 'data'\n",
    "batch_size = 32\n",
    "num_workers = 5\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c179e6c9-b518-4137-993f-4ef4279f46ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(30), \n",
    "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "data_transforms['test'] = data_transforms['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "789853a2-3983-4ab6-b86e-ae2b2689ab2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names found: ['fist', 'like', 'no_gesture', 'palm']\n",
      "4 classes detected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/GestureControl/gesturevenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load the datasets using ImageFolder\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "                  for x in ['train', 'val', 'test']}\n",
    "\n",
    "# create the dataloaders\n",
    "dataloaders = {\n",
    "    'train': DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True),\n",
    "    'val': DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True),\n",
    "    'test': DataLoader(image_datasets['test'], batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "num_classes = len(class_names)\n",
    "print(\"Class names found:\", class_names)\n",
    "print(f\"{num_classes} classes detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45987e6d-8520-45ce-9d0e-7ab9286f3fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-7ebf99e0.pth\" to /home/ec2-user/.cache/torch/hub/checkpoints/mobilenet_v2-7ebf99e0.pth\n",
      "100%|██████████| 13.6M/13.6M [00:00<00:00, 243MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n",
    "\n",
    "# freeze all layers first\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the last few convolutional blocks\n",
    "for param in model.features[-5:].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Replace the classifier head, making sure its parameters are trainable\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dedca7f-8d24-4350-9cbd-7ab1c00703fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model.features.parameters(), 'lr': 1e-5}, \n",
    "    {'params': model.classifier.parameters(), 'lr': 1e-3}\n",
    "])\n",
    "\n",
    "# set up a learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbce60c-e4b4-4c2a-a14d-fc4655f02fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [1:10:43<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6444 Acc: 0.7283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 288/288 [06:54<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2870 Acc: 0.8898\n",
      "\n",
      "Epoch 2/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [21:57<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4063 Acc: 0.8364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 288/288 [02:40<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2163 Acc: 0.9191\n",
      "\n",
      "Epoch 3/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [21:58<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3428 Acc: 0.8613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 288/288 [02:41<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1873 Acc: 0.9286\n",
      "\n",
      "Epoch 4/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [22:00<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3063 Acc: 0.8763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [21:52<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2777 Acc: 0.8895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [21:49<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2568 Acc: 0.8967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 288/288 [02:41<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1526 Acc: 0.9439\n",
      "\n",
      "Epoch 7/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 288/288 [02:41<00:00,  1.78it/s]t/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1436 Acc: 0.9448\n",
      "\n",
      "Epoch 8/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [21:37<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2290 Acc: 0.9083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 288/288 [02:39<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1373 Acc: 0.9486\n",
      "\n",
      "Epoch 9/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [21:29<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2274 Acc: 0.9104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 288/288 [02:39<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1369 Acc: 0.9475\n",
      "\n",
      "Epoch 10/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [21:30<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2281 Acc: 0.9101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 288/288 [02:39<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1360 Acc: 0.9476\n",
      "\n",
      "Epoch 11/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [21:29<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2214 Acc: 0.9127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 288/288 [02:40<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1375 Acc: 0.9474\n",
      "\n",
      "Epoch 12/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [21:28<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2229 Acc: 0.9120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 288/288 [02:39<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1362 Acc: 0.9486\n",
      "\n",
      "Epoch 13/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [21:25<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2202 Acc: 0.9123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 288/288 [02:39<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1352 Acc: 0.9489\n",
      "\n",
      "Epoch 14/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [21:26<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2162 Acc: 0.9147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 288/288 [02:38<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1349 Acc: 0.9493\n",
      "\n",
      "Epoch 15/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [21:31<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2197 Acc: 0.9133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 288/288 [02:39<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1345 Acc: 0.9499\n",
      "\n",
      "Epoch 16/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [21:40<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2174 Acc: 0.9143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 288/288 [02:38<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1356 Acc: 0.9499\n",
      "\n",
      "Epoch 17/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [21:36<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2186 Acc: 0.9146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 288/288 [02:38<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1319 Acc: 0.9509\n",
      "\n",
      "Epoch 18/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [21:42<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2185 Acc: 0.9128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 288/288 [02:38<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1328 Acc: 0.9502\n",
      "\n",
      "Epoch 19/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [21:36<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2199 Acc: 0.9123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 288/288 [02:39<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1313 Acc: 0.9513\n",
      "\n",
      "Epoch 20/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [21:35<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2168 Acc: 0.9134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 288/288 [02:38<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1343 Acc: 0.9500\n",
      "\n",
      "Epoch 21/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [21:40<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2194 Acc: 0.9135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 288/288 [02:38<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1348 Acc: 0.9497\n",
      "\n",
      "Epoch 22/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [21:37<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2167 Acc: 0.9138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 288/288 [02:38<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1361 Acc: 0.9487\n",
      "\n",
      "Epoch 23/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [21:37<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2177 Acc: 0.9140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 288/288 [02:39<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1325 Acc: 0.9513\n",
      "\n",
      "Epoch 24/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2249/2249 [21:32<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2173 Acc: 0.9139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 288/288 [02:38<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1318 Acc: 0.9508\n",
      "\n",
      "Early stopping triggered after 5 epochs with no improvement.\n",
      "Training complete in 637m 3s\n",
      "Best val Acc: 0.951304\n",
      "Best model weights have been loaded.\n",
      "Model successfully saved to: gesture_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50 \n",
    "patience = 5  # number of epochs to wait for improvement before stopping\n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "\n",
    "start_time = time.time()\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in tqdm(dataloaders[phase], desc=phase):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        # early stopping\n",
    "        if phase == 'val':\n",
    "            # if validation accuracy has improved, save the model and reset the counter\n",
    "            if epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                epochs_no_improve = 0\n",
    "            # if validation accuracy has not improved, increment the counter\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "    \n",
    "    # check if we should stop after each epoch\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f'\\nEarly stopping triggered after {patience} epochs with no improvement.')\n",
    "        early_stop = True\n",
    "        break  \n",
    "\n",
    "    scheduler.step()\n",
    "    print()\n",
    "\n",
    "time_elapsed = time.time() - start_time\n",
    "print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "# load the best model weights found during training\n",
    "model.load_state_dict(best_model_wts)\n",
    "print(\"Best model weights have been loaded.\")\n",
    "save_path = 'gesture_best.pth'\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model successfully saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b9c487e-225c-423f-a704-bfd1c98a942e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afa95d9-a9c7-44f4-bb5f-a1c260964f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be537db-0565-4ba9-9279-98ec52102ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Gesture Venv)",
   "language": "python",
   "name": "gesture-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
